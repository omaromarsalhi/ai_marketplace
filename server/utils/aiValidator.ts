import { Ollama } from 'ollama'
import { readFile } from 'fs/promises'
import { join } from 'path'

// Configuration
const ollamaApiKey = process.env.OLLAMA_API_KEY
const groqApiKey = process.env.GROQ_API_KEY

// Model configuration via environment variables
const ollamaTextModel = process.env.OLLAMA_CLOUD_TEXT_MODEL || 'qwen2.5:3b'
const ollamaVisionModel = process.env.OLLAMA_CLOUD_VISION_MODEL || 'llava:7b-v1.6-mistral-q2_K'
const groqTextModel = process.env.GROQ_TEXT_MODEL || 'llama3-8b-8192'
const groqVisionModel = process.env.GROQ_VISION_MODEL || 'qwen2-vl-7b-instruct'

// Provider selection
const visionProvider = process.env.VISION_PROVIDER || 'gemini'
const textProvider = process.env.TEXT_PROVIDER || 'ollama'

// Ollama Cloud configuration
const ollamaHost = 'https://api.ollama.cloud'
const ollamaHeaders: Record<string, string> = {}
if (ollamaApiKey) {
  ollamaHeaders['Authorization'] = `Bearer ${ollamaApiKey}`
}

console.log(`ü§ñ Ollama Provider: CLOUD`)
console.log(`üåê Ollama Host: ${ollamaHost}`)
console.log(`üîÆ Vision Provider: ${visionProvider.toUpperCase()}`)
console.log(`üìù Text Provider: ${textProvider.toUpperCase()}`)
console.log(`üìù Text Model (Ollama): ${ollamaTextModel}`)
console.log(`üñºÔ∏è  Vision Model (Ollama): ${ollamaVisionModel}`)
console.log(`‚ö° Text Model (Groq): ${groqTextModel}`)
console.log(`üëÅÔ∏è Vision Model (Groq): ${groqVisionModel}`)
console.log(`üîë Ollama API Key: ${ollamaApiKey ? 'Configured' : 'Not configured'}`)
console.log(`üîë Groq API Key: ${groqApiKey ? 'Configured' : 'Not configured'}`)

// Initialize Ollama client
const ollama = new Ollama({
  host: ollamaHost,
  headers: ollamaHeaders
})

export interface ValidationResult {
  isValid: boolean
  score: number // 0-100
  issues: string[]
  imageDescription: string
  reasoning: string
}

/**
 * Describe the image using Ollama vision model

/**
 * Describe the image using Ollama LLaVA vision model
 */
async function describeImageWithOllama(imageUrl: string): Promise<string> {
  console.log('üîç Analyzing image with Ollama LLaVA vision model...')
  
  // Check configuration
  if (!ollamaApiKey) {
    throw new Error('Ollama API key is not configured. Please set OLLAMA_API_KEY in your .env file')
  }
  
  let base64Image: string
  
  // Check if the URL is a relative path (local file)
  if (imageUrl.startsWith('/')) {
    // It's a relative path, read from file system
    const filePath = join(process.cwd(), 'public', imageUrl)
    console.log(`üìÅ Reading local file: ${filePath}`)
    const fileBuffer = await readFile(filePath)
    base64Image = fileBuffer.toString('base64')
  } else {
    // It's a full URL, fetch it
    console.log(`üåê Fetching remote image: ${imageUrl}`)
    const imageResponse = await fetch(imageUrl)
    if (!imageResponse.ok) {
      throw new Error(`Failed to fetch image: ${imageResponse.statusText}`)
    }
    const imageBuffer = await imageResponse.arrayBuffer()
    base64Image = Buffer.from(imageBuffer).toString('base64')
  }
  
  // Use Ollama LLaVA vision model to describe the image
  console.log('ü§ñ Sending image to Ollama LLaVA...')
  
  // Use configured vision model
  const visionModel = ollamaVisionModel
  
  const response = await ollama.generate({
    model: visionModel,
    prompt: 'Describe this product image in detail. Focus on: what the product is, its color, texture, condition, packaging (if any), and any visible text or branding. Be specific and objective.',
    images: [base64Image],
    stream: false
  })
  
  console.log('‚úÖ Image description generated by Ollama LLaVA')
  console.log('üìù Ollama LLaVA Description:', response.response)
  return response.response
}

/**
 * Describe the image using the configured vision provider (Ollama or Groq)
 */
async function describeImage(imageUrl: string): Promise<string> {
  try {
    if (visionProvider === 'groq') {
      return await describeImageWithGroq(imageUrl)
    } else {
      // Default to Ollama
      return await describeImageWithOllama(imageUrl)
    }
  } catch (error: any) {
    console.error('‚ùå Error describing image:', error.message)
    
    // Provide specific error messages
    if (error.message.includes('API key')) {
      throw new Error(`${visionProvider.toUpperCase()} API key not configured. Check your .env file`)
    }
    throw new Error(`Failed to analyze image: ${error.message}`)
  }
}

/**
 * Generate text using Groq
 */
async function generateTextWithGroq(prompt: string): Promise<string> {
  if (!groqApiKey) {
    throw new Error('Groq API key not configured')
  }

  console.log('üöÄ Generating text with Groq...')
  
  try {
    const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${groqApiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: groqTextModel,
        messages: [
          {
            role: 'user',
            content: prompt
          }
        ],
        temperature: 0.7,
        max_tokens: 1000
      })
    })

    if (!response.ok) {
      const errorData = await response.text()
      throw new Error(`Groq API error: ${response.status} - ${errorData}`)
    }

    const data = await response.json()
    
    if (!data.choices || !data.choices[0] || !data.choices[0].message) {
      throw new Error('Invalid response from Groq API')
    }

    const result = data.choices[0].message.content
    console.log('‚úÖ Text generated by Groq')
    return result
    
  } catch (error: any) {
    console.error('‚ùå Error with Groq:', error.message)
    throw new Error(`Groq generation failed: ${error.message}`)
  }
}

/**
 * Describe image using Groq vision model
 */
async function describeImageWithGroq(imageUrl: string): Promise<string> {
  if (!groqApiKey) {
    throw new Error('Groq API key not configured')
  }

  console.log('üöÄ Analyzing image with Groq vision model...')
  
  try {
    let imageUrlOrBase64: string
    
    // Check if the URL is a relative path (local file)
    if (imageUrl.startsWith('/')) {
      // It's a relative path, read from file system and convert to base64
      const filePath = join(process.cwd(), 'public', imageUrl)
      console.log(`üìÅ Reading local file for Groq: ${filePath}`)
      const fileBuffer = await readFile(filePath)
      const base64Image = fileBuffer.toString('base64')
      
      // Determine the image type from the file extension
      const extension = imageUrl.split('.').pop()?.toLowerCase()
      const mimeType = extension === 'png' ? 'image/png' : 
                       extension === 'jpg' || extension === 'jpeg' ? 'image/jpeg' : 
                       extension === 'gif' ? 'image/gif' : 
                       extension === 'webp' ? 'image/webp' : 
                       'image/jpeg' // default
      
      imageUrlOrBase64 = `data:${mimeType};base64,${base64Image}`
      console.log('‚úÖ Image converted to base64 for Groq')
    } else {
      // It's a full URL, use it directly
      console.log(`üåê Using remote image URL: ${imageUrl}`)
      imageUrlOrBase64 = imageUrl
    }
    
    const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${groqApiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: groqVisionModel,
        messages: [
          {
            role: 'user',
            content: [
              { 
                type: 'text', 
                text: 'Describe this product image in detail. Focus on: what the product is, its color, texture, condition, packaging (if any), and any visible text or branding. Be specific and objective.' 
              },
              {
                type: 'image_url',
                image_url: {
                  url: imageUrlOrBase64
                }
              }
            ]
          }
        ],
        temperature: 0.3,
        max_tokens: 1000
      })
    })

    if (!response.ok) {
      const errorData = await response.text()
      throw new Error(`Groq Vision API error: ${response.status} - ${errorData}`)
    }

    const data = await response.json()
    
    if (!data.choices || !data.choices[0] || !data.choices[0].message) {
      throw new Error('Invalid response from Groq Vision API')
    }

    const description = data.choices[0].message.content
    console.log('‚úÖ Image description generated by Groq')
    console.log('üìù Groq Vision Description:', description)
    return description
    
  } catch (error: any) {
    console.error('‚ùå Error with Groq Vision:', error.message)
    throw new Error(`Groq vision analysis failed: ${error.message}`)
  }
}

/**
 * Generate text using the configured text provider (Groq or Ollama)
 */
async function generateText(prompt: string): Promise<string> {
  try {
    if (textProvider === 'groq') {
      return await generateTextWithGroq(prompt)
    } else {
      // Default to Ollama
      const response = await ollama.generate({
        model: ollamaTextModel,
        prompt,
        stream: false,
        options: {
          temperature: 0.7
        }
      })
      return response.response
    }
  } catch (error: any) {
    console.error('‚ùå Error generating text:', error.message)
    throw new Error(`Failed to generate text: ${error.message}`)
  }
}


/**
 * Validate product data against image description
 */
async function validateProductData(
  title: string,
  description: string,
  imageDescription: string
): Promise<{ isValid: boolean; score: number; issues: string[]; reasoning: string }> {
  try {
    console.log(`ü§ñ Validating product data with ${textProvider.toUpperCase()}...`)
    
    const prompt = `You are a product validation AI. Your job is to verify if the product information matches the image.

IMAGE DESCRIPTION:
${imageDescription}

PRODUCT TITLE:
${title}

PRODUCT DESCRIPTION:
${description}

TASK:
1. Check if the title accurately represents what's in the image
2. Check if the description matches the image content
3. Identify any mismatches or misleading information
4. Give a validation score (0-100) where:
   - 90-100: Perfect match, no issues
   - 70-89: Good match, minor inconsistencies
   - 50-69: Moderate issues, needs review
   - 0-49: Poor match, significant problems

Respond in this EXACT JSON format (no additional text):
{
  "isValid": true or false (true if score >= 70),
  "score": number between 0-100,
  "issues": ["list", "of", "specific", "issues", "found"],
  "reasoning": "brief explanation of your decision"
}

If issues array is empty and everything matches perfectly, set issues to empty array [].`

    // Use the configured text provider
    const response = await generateText(prompt)
    
    // Parse the AI response
    const jsonMatch = response.match(/\{[\s\S]*\}/)
    if (!jsonMatch) {
      throw new Error('Invalid AI response format')
    }
    
    const result = JSON.parse(jsonMatch[0])
    
    console.log(`‚úÖ Validation complete - Score: ${result.score}/100`)
    return result
  } catch (error: any) {
    console.error('‚ùå Error validating product:', error.message)
    throw new Error(`Failed to validate product: ${error.message}`)
  }
}

/**
 * Main validation function
 */
export async function validateProductWithAI(
  title: string,
  description: string,
  imageUrl: string
): Promise<ValidationResult> {
  try {
    // Step 1: Describe the image
    const imageDescription = await describeImage(imageUrl)
    
    // Step 2: Validate product data against image description
    const validation = await validateProductData(title, description, imageDescription)
    
    return {
      ...validation,
      imageDescription
    }
  } catch (error: any) {
    console.error('‚ùå AI Validation failed:', error.message)
    throw error
  }
}

/**
 * Check if Ollama is available
 */
export async function checkOllamaHealth(): Promise<boolean> {
  try {
    await ollama.list()
    return true
  } catch (error) {
    console.error('‚ö†Ô∏è Ollama is not available:', error)
    return false
  }
}

/**
 * Check if required models are available
 */
export async function checkRequiredModels(): Promise<{ vision: boolean; text: boolean; message: string }> {
  try {
    // Check vision provider configuration (Ollama or Groq)
    const hasVision = visionProvider === 'groq' ? !!groqApiKey : !!ollamaApiKey
    
    // For text models, check if either Ollama or Groq API key is available
    const hasText = !!ollamaApiKey || !!groqApiKey

    let message = ''
    if (!hasVision && !hasText) {
      message = 'Missing API keys for both vision and text. Set appropriate API keys in your .env file'
    } else if (!hasVision) {
      const visionProviderName = visionProvider === 'groq' ? 'Groq' : 'Ollama'
      const visionKeyName = visionProvider === 'groq' ? 'GROQ_API_KEY' : 'OLLAMA_API_KEY'
      message = `Missing ${visionProviderName} API key for vision. Set ${visionKeyName} in your .env file`
    } else if (!hasText) {
      message = 'Missing API keys for text generation. Set either OLLAMA_API_KEY or GROQ_API_KEY in your .env file'
    } else {
      const visionProviderName = visionProvider === 'groq' ? 'Groq' : 'Ollama'
      const textProviderName = textProvider === 'groq' ? 'Groq' : 'Ollama'
      message = `‚úÖ All required models are available (${visionProviderName} Vision + ${textProviderName} Text)`
    }
    
    return { vision: hasVision, text: hasText, message }
  } catch (error) {
    // If there's any error, check what's available
    const hasVision = visionProvider === 'groq' ? !!groqApiKey : !!ollamaApiKey
    const hasText = !!ollamaApiKey || !!groqApiKey
    return { 
      vision: hasVision, 
      text: hasText, 
      message: 'Error checking models availability'
    }
  }
}

// Export the generateText function for use in other modules
export { generateText }