import { Ollama } from 'ollama'
import { readFile } from 'fs/promises'
import { join } from 'path'

// Initialize Ollama client for Ollama Cloud
const ollamaHost = 'https://api.ollama.cloud'
const ollamaApiKey = process.env.OLLAMA_API_KEY
const geminiApiKey = process.env.GEMINI_API_KEY
const visionProvider = process.env.VISION_PROVIDER || 'gemini' // 'gemini' or 'ollama'

// Check if using cloud or local
const isUsingCloud = true

console.log(`ü§ñ Using Ollama Cloud: ${ollamaHost}`)
console.log(`üîÆ Vision Provider: ${visionProvider.toUpperCase()}`)
console.log(`üîÆ Gemini API Key: ${geminiApiKey ? 'Configured' : 'Not configured'}`)
console.log(`üîë Ollama API Key: ${ollamaApiKey ? 'Configured' : 'Not configured'}`)

// Initialize Ollama Cloud client according to docs
const ollama = new Ollama({
  host: ollamaHost,
  headers: {
    'Authorization': `Bearer ${ollamaApiKey}`
  }
})

export interface ValidationResult {
  isValid: boolean
  score: number // 0-100
  issues: string[]
  imageDescription: string
  reasoning: string
}

/**
 * Describe the image using Gemini vision model
 */
async function describeImageWithGemini(imageUrl: string): Promise<string> {
  console.log('üîç Analyzing image with Google Gemini vision model...')
  
  if (!geminiApiKey) {
    throw new Error('Gemini API key is not configured. Please set GEMINI_API_KEY in your .env file')
  }
  
  let base64Image: string
  let mimeType: string = 'image/jpeg'
  
  // Check if the URL is a relative path (local file)
  if (imageUrl.startsWith('/')) {
    // It's a relative path, read from file system
    const filePath = join(process.cwd(), 'public', imageUrl)
    console.log(`üìÅ Reading local file: ${filePath}`)
    const fileBuffer = await readFile(filePath)
    base64Image = fileBuffer.toString('base64')
    
    // Detect mime type from file extension
    if (filePath.endsWith('.png')) mimeType = 'image/png'
    else if (filePath.endsWith('.webp')) mimeType = 'image/webp'
    else if (filePath.endsWith('.gif')) mimeType = 'image/gif'
  } else {
    // It's a full URL, fetch it
    console.log(`üåê Fetching remote image: ${imageUrl}`)
    const imageResponse = await fetch(imageUrl)
    if (!imageResponse.ok) {
      throw new Error(`Failed to fetch image: ${imageResponse.statusText}`)
    }
    const imageBuffer = await imageResponse.arrayBuffer()
    base64Image = Buffer.from(imageBuffer).toString('base64')
    mimeType = imageResponse.headers.get('content-type') || 'image/jpeg'
  }
  
  // Use Google Gemini vision model to describe the image
  console.log('ü§ñ Sending image to Google Gemini...')
  const response = await fetch(
    `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?key=${geminiApiKey}`,
    {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        contents: [{
          parts: [
            {
              text: 'Describe this product image in detail. Focus on: what the product is, its color, texture, condition, packaging (if any), and any visible text or branding. Be specific and objective.'
            },
            {
              inline_data: {
                mime_type: mimeType,
                data: base64Image
              }
            }
          ]
        }]
      })
    }
  )
  
  if (!response.ok) {
    const error = await response.text()
    throw new Error(`Gemini API error: ${response.status} - ${error}`)
  }
  
  const data = await response.json()
  const description = data.candidates?.[0]?.content?.parts?.[0]?.text
  
  if (!description) {
    throw new Error('No description returned from Gemini')
  }
  
  console.log('‚úÖ Image description generated by Gemini')
  console.log('üìù Gemini Description:', description)
  return description
}

/**
 * Describe the image using Ollama LLaVA vision model
 */
async function describeImageWithOllama(imageUrl: string): Promise<string> {
  console.log('üîç Analyzing image with Ollama LLaVA vision model...')
  
  if (!ollamaApiKey) {
    throw new Error('Ollama API key is not configured. Please set OLLAMA_API_KEY in your .env file')
  }
  
  let base64Image: string
  
  // Check if the URL is a relative path (local file)
  if (imageUrl.startsWith('/')) {
    // It's a relative path, read from file system
    const filePath = join(process.cwd(), 'public', imageUrl)
    console.log(`üìÅ Reading local file: ${filePath}`)
    const fileBuffer = await readFile(filePath)
    base64Image = fileBuffer.toString('base64')
  } else {
    // It's a full URL, fetch it
    console.log(`üåê Fetching remote image: ${imageUrl}`)
    const imageResponse = await fetch(imageUrl)
    if (!imageResponse.ok) {
      throw new Error(`Failed to fetch image: ${imageResponse.statusText}`)
    }
    const imageBuffer = await imageResponse.arrayBuffer()
    base64Image = Buffer.from(imageBuffer).toString('base64')
  }
  
  // Use Ollama LLaVA vision model to describe the image
  console.log('ü§ñ Sending image to Ollama LLaVA...')
  const response = await ollama.generate({
    model: 'llava:7b-v1.6-mistral-q2_K',
    prompt: 'Describe this product image in detail. Focus on: what the product is, its color, texture, condition, packaging (if any), and any visible text or branding. Be specific and objective.',
    images: [base64Image],
    stream: false
  })
  
  console.log('‚úÖ Image description generated by Ollama LLaVA')
  console.log('üìù Ollama LLaVA Description:', response.response)
  return response.response
}

/**
 * Describe the image using the configured vision provider
 */
async function describeImage(imageUrl: string): Promise<string> {
  try {
    if (visionProvider === 'ollama') {
      return await describeImageWithOllama(imageUrl)
    } else {
      return await describeImageWithGemini(imageUrl)
    }
  } catch (error: any) {
    console.error('‚ùå Error describing image:', error.message)
    
    // Provide specific error messages
    if (error.message.includes('API key')) {
      throw new Error(`${visionProvider.toUpperCase()} API key not configured. Check your .env file`)
    }
    throw new Error(`Failed to analyze image: ${error.message}`)
  }
}


/**
 * Validate product data against image description
 */
async function validateProductData(
  title: string,
  description: string,
  imageDescription: string
): Promise<{ isValid: boolean; score: number; issues: string[]; reasoning: string }> {
  try {
    console.log('ü§ñ Validating product data with Llama 3.2 (Ollama Cloud)...')
    
    const prompt = `You are a product validation AI. Your job is to verify if the product information matches the image.

IMAGE DESCRIPTION:
${imageDescription}

PRODUCT TITLE:
${title}

PRODUCT DESCRIPTION:
${description}

TASK:
1. Check if the title accurately represents what's in the image
2. Check if the description matches the image content
3. Identify any mismatches or misleading information
4. Give a validation score (0-100) where:
   - 90-100: Perfect match, no issues
   - 70-89: Good match, minor inconsistencies
   - 50-69: Moderate issues, needs review
   - 0-49: Poor match, significant problems

Respond in this EXACT JSON format (no additional text):
{
  "isValid": true or false (true if score >= 70),
  "score": number between 0-100,
  "issues": ["list", "of", "specific", "issues", "found"],
  "reasoning": "brief explanation of your decision"
}

If issues array is empty and everything matches perfectly, set issues to empty array [].`

    // Use llama3.2:latest - available on your Ollama Cloud account
    const response = await ollama.generate({
      model: 'llama3.2:latest',
      prompt,
      stream: false,
      options: {
        temperature: 0.3, // Lower temperature for more consistent outputs
      }
    })
    
    // Parse the AI response
    const jsonMatch = response.response.match(/\{[\s\S]*\}/)
    if (!jsonMatch) {
      throw new Error('Invalid AI response format')
    }
    
    const result = JSON.parse(jsonMatch[0])
    
    console.log(`‚úÖ Validation complete - Score: ${result.score}/100`)
    return result
  } catch (error: any) {
    console.error('‚ùå Error validating product:', error.message)
    
    // Provide specific error messages
    if (error.message.includes('not found')) {
      throw new Error('Llama 3.2 model not available. Check your OLLAMA_API_KEY or available models')
    }
    throw new Error(`Failed to validate product: ${error.message}`)
  }
}

/**
 * Main validation function
 */
export async function validateProductWithAI(
  title: string,
  description: string,
  imageUrl: string
): Promise<ValidationResult> {
  try {
    // Step 1: Describe the image
    const imageDescription = await describeImage(imageUrl)
    
    // Step 2: Validate product data against image description
    const validation = await validateProductData(title, description, imageDescription)
    
    return {
      ...validation,
      imageDescription
    }
  } catch (error: any) {
    console.error('‚ùå AI Validation failed:', error.message)
    throw error
  }
}

/**
 * Check if Ollama is available
 */
export async function checkOllamaHealth(): Promise<boolean> {
  try {
    await ollama.list()
    return true
  } catch (error) {
    console.error('‚ö†Ô∏è Ollama is not available:', error)
    return false
  }
}

/**
 * Check if required models are available
 */
export async function checkRequiredModels(): Promise<{ vision: boolean; text: boolean; message: string }> {
  try {
    // Check vision provider based on configuration
    let hasVision = false
    if (visionProvider === 'ollama') {
      // For Ollama vision, check if API key is available
      hasVision = !!ollamaApiKey
    } else {
      // For Gemini vision, check if API key is available
      hasVision = !!geminiApiKey
    }
    
    // For Ollama Cloud text model, we just need the API key - cloud models are always available
    const hasText = !!ollamaApiKey && isUsingCloud
    
    let message = ''
    if (!hasVision && !hasText) {
      if (visionProvider === 'ollama') {
        message = 'Missing Ollama API key for both vision and text. Set OLLAMA_API_KEY in your .env file'
      } else {
        message = 'Missing Gemini API key and Ollama Cloud API key. Set both in your .env file'
      }
    } else if (!hasVision) {
      if (visionProvider === 'ollama') {
        message = 'Missing Ollama API key for vision. Set OLLAMA_API_KEY in your .env file'
      } else {
        message = 'Missing Gemini API key for vision. Set GEMINI_API_KEY in your .env file'
      }
    } else if (!hasText) {
      message = 'Missing Ollama Cloud API key for text validation. Set OLLAMA_API_KEY in your .env file'
    } else {
      const visionMsg = visionProvider === 'ollama' ? 'Ollama LLaVA' : 'Gemini'
      message = `‚úÖ All required models are available (${visionMsg} + Ollama Cloud)`
    }
    
    return { vision: hasVision, text: hasText, message }
  } catch (error) {
    // If there's any error, check what's available
    const hasVision = visionProvider === 'ollama' ? !!ollamaApiKey : !!geminiApiKey
    const hasText = !!ollamaApiKey
    return { 
      vision: hasVision, 
      text: hasText, 
      message: 'Error checking models availability'
    }
  }
}
